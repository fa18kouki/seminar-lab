{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fashion-MNISTデータセットを使用した画像分類モデルの実装\n","\n","このノートブックでは、PyTorchを使用してFashion-MNISTデータセットの画像分類を行うニューラルネットワークモデルを実装します。\n","\n","主な実装内容:\n","- Fashion-MNISTデータセットのダウンロードと前処理\n","- データローダーの設定\n","- ニューラルネットワークモデルの定義\n","- モデルの学習と評価\n","\n","Fashion-MNISTは10種類の衣類画像からなるデータセットで、各画像は28x28ピクセルのグレースケール画像です。\n"]},{"cell_type":"markdown","metadata":{},"source":["# 必要なライブラリのインポートとデータセットの準備\n","\n","このコードでは以下の処理を行っています:\n","\n","1. PyTorchおよび関連ライブラリのインポート\n","2. Fashion-MNISTデータセットのダウンロードと前処理\n","   - 訓練データとテストデータの準備\n","   - ToTensor()による画像データの正規化\n","3. データローダーの設定\n","   - バッチサイズ: 64\n","4. 10クラスのラベル定義（日本語）\n","5. 実行デバイスの設定（GPU/MPS/CPU）\n","6. 学習・評価用の関数定義\n","   - train(): モデルの学習を行う関数\n","   - test(): モデルの評価を行う関数\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n","# データセットの準備\n","# Fashion-MNISTデータセットをダウンロードして前処理\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# データローダーの設定\n","batch_size = 64\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","# クラスラベルの定義\n","classes = [\n","    \"Tシャツ/トップ\", \"ズボン\", \"プルオーバー\", \"ドレス\", \"コート\",\n","    \"サンダル\", \"シャツ\", \"スニーカー\", \"バッグ\", \"アンクルブーツ\"\n","]\n","\n","# デバイスの設定（GPU/MPS/CPU）\n","device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","\n","\n","\n","# 学習用の関数定義\n","def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"損失: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","# テスト用の関数定義\n","def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"テスト結果: \\n 精度: {(100*correct):>0.1f}%, 平均損失: {test_loss:>8f} \\n\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# ニューラルネットワークの構築"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ニューラルネットワークモデルの定義\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{},"source":["# モデルの学習と評価\n","定義したニューラルネットワークモデルをインスタンス化し、損失関数とオプティマイザを設定します。\n","その後、5エポックにわたってモデルの学習を行い、各エポック終了時にテストデータでモデルの評価を実施します。\n","train()関数で訓練を行い、test()関数でモデルの精度と損失を確認します。\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# モデルのインスタンス化\n","model = NeuralNetwork().to(device)\n","\n","# 損失関数とオプティマイザの設定\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n","# 学習の実行\n","epochs = 5\n","for t in range(epochs):\n","    print(f\"エポック {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_iter = iter(test_dataloader)\n","testX, testy = next(test_iter)\n","pred = model(testX.to(device))\n","plt.imshow(testX[0].numpy().reshape(28, 28))\n","print('True      Label:', classes[testy[0].item()])\n","print('Estimated Label:', classes[pred.argmax(1)[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# モデルの保存\n","torch.save(model.state_dict(), \"model.pth\")\n","\n","# モデルの読み込み\n","model = NeuralNetwork().to(device)\n","model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
